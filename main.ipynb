{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213d3f8e1bfab17",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def augment_and_extract_metadata(dataset, extractor, topic_labels, file_path, debug=False):\n",
    "    if os.path.exists(file_path):\n",
    "        # If the file exists, load the augmented dataset from the CSV file\n",
    "        print(f\"Loading augmented dataset from {file_path}\")\n",
    "        augmented_dataset = pd.read_csv(file_path)\n",
    "    else:\n",
    "        # If the file does not exist, proceed with augmenting the dataset\n",
    "        print(f\"Augmenting dataset and saving to {file_path}\")\n",
    "        total_rows = len(dataset)\n",
    "        count = 0\n",
    "\n",
    "        topics = []\n",
    "\n",
    "        # Iterate over each row in the dataset\n",
    "        for index, row in dataset.iterrows():\n",
    "            # Extract topic using the extractor\n",
    "            topic = extractor.extract_topic(row['text'], topic_labels)\n",
    "            topics.append(topic)\n",
    "\n",
    "            for label in topic_labels:\n",
    "                dataset.at[index, label] = 1 if topic == label else 0\n",
    "\n",
    "            # If debug mode is enabled, print debug information\n",
    "            percentage_complete = ((count + 1) / total_rows) * 100\n",
    "            if debug:\n",
    "                print(f\"Text: {row['text']}\")\n",
    "                print(f\"Generated Metadata: Topic - {topic}\")\n",
    "                print(f\"Percentage of Completion: {percentage_complete:.2f}%, {count + 1} of {total_rows}\")\n",
    "\n",
    "            if percentage_complete % 5 == 0:\n",
    "                print(f\"Percentage of Completion: {percentage_complete:.2f}%, {count + 1} of {total_rows}\")\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        dataset['topic'] = topics\n",
    "\n",
    "        dataset.to_csv(file_path, index=False)\n",
    "        augmented_dataset = dataset\n",
    "\n",
    "    return augmented_dataset\n",
    "\n",
    "\n",
    "def predict_sentiment(dataset, sentiment_analyzer, file_path, debug=False, batch_size=32):\n",
    "    if os.path.exists(file_path):\n",
    "        # If the file exists, load the sentiment-augmented dataset from the CSV file\n",
    "        print(f\"Loading sentiment-augmented dataset from {file_path}\")\n",
    "        sentiment_augmented_dataset = pd.read_csv(file_path)\n",
    "    else:\n",
    "        # If the file does not exist, proceed with sentiment prediction\n",
    "        print(f\"Predicting sentiment and saving to {file_path}\")\n",
    "        total_rows = len(dataset)\n",
    "        sentiments = []\n",
    "\n",
    "        # Process the dataset in batches\n",
    "        for start in range(0, total_rows, batch_size):\n",
    "            end = min(start + batch_size, total_rows)\n",
    "            # Extract a batch of texts from the dataset\n",
    "            batch_texts = dataset['text'][start:end].tolist()\n",
    "            # Use the sentiment analyzer to classify the sentiments of the batch of texts\n",
    "            batch_results = sentiment_analyzer.classifier(batch_texts)\n",
    "            # Map the sentiment labels to target values for each result in the batch\n",
    "            batch_sentiments = [sentiment_analyzer.map_label_to_target(result['label']) for result in batch_results]\n",
    "            # Extend the sentiments list with the batch sentiments\n",
    "            sentiments.extend(batch_sentiments)\n",
    "            # Calculate the percentage of completion\n",
    "            percentage_complete = ((end) / total_rows) * 100\n",
    "            if debug:\n",
    "                print(f\"Processed batch {start // batch_size + 1}: {start} to {end}\")\n",
    "                print(f\"Percentage of Completion: {percentage_complete:.2f}%, {end} of {total_rows}\")\n",
    "            if percentage_complete % 5 == 0:\n",
    "                print(f\"Percentage of Completion: {percentage_complete:.2f}%\")\n",
    "\n",
    "        dataset['sentiment'] = sentiments\n",
    "        dataset.to_csv(file_path, index=False)\n",
    "        sentiment_augmented_dataset = dataset\n",
    "\n",
    "    return sentiment_augmented_dataset"
   ],
   "id": "ca091c046672798"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MetadataExtractor:\n",
    "    def __init__(self):\n",
    "        # Check if GPUs are available and set the devices accordingly\n",
    "        self.devices = [i for i in range(torch.cuda.device_count())]\n",
    "\n",
    "        # Initialize the zero-shot classification pipelines with specific models\n",
    "        self.MODEL = \"roberta-large-mnli\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.MODEL)\n",
    "        self.models = [\n",
    "            AutoModelForSequenceClassification.from_pretrained(self.MODEL, ignore_mismatched_sizes=True).to(f'cuda:{device}')\n",
    "            for device in self.devices\n",
    "        ]\n",
    "        self.classifiers = [\n",
    "            pipeline(\"zero-shot-classification\", model=model, tokenizer=self.tokenizer, device=device)\n",
    "            for model, device in zip(self.models, self.devices)\n",
    "        ]\n",
    "        self.current_device_index = 0\n",
    "\n",
    "    def _get_next_classifier(self):\n",
    "        \"\"\"\n",
    "        Get the next classifier in a round-robin manner to distribute the workload.\n",
    "        \"\"\"\n",
    "        classifier = self.classifiers[self.current_device_index]\n",
    "        self.current_device_index = (self.current_device_index + 1) % len(self.devices)\n",
    "        return classifier\n",
    "\n",
    "    def extract_attribute(self, text, candidate_labels, hypothesis_template):\n",
    "        \"\"\"\n",
    "        Extracts an attribute from the given text using the zero-shot classification model.\n",
    "\n",
    "        :param text: The text to classify.\n",
    "        :param candidate_labels: A list of strings representing candidate labels.\n",
    "        :param hypothesis_template: A template for the hypothesis.\n",
    "        :return: The label with the highest probability.\n",
    "        \"\"\"\n",
    "        # Get the classifier for the current task\n",
    "        classifier = self._get_next_classifier()\n",
    "        # Perform zero-shot classification\n",
    "        result = classifier(text, candidate_labels, hypothesis_template=hypothesis_template)\n",
    "        # Get the label with the highest probability\n",
    "        top_label = result['labels'][0]\n",
    "        return top_label\n",
    "\n",
    "    def extract_topic(self, text, candidate_labels):\n",
    "        \"\"\"\n",
    "        Extracts the topic from the given text.\n",
    "\n",
    "        :param candidate_labels:\n",
    "        :param text: The text to classify.\n",
    "        :return: The topic label with the highest probability.\n",
    "        \"\"\"\n",
    "        hypothesis_template = \"The topic of this text is {}.\"\n",
    "        return self.extract_attribute(text, candidate_labels, hypothesis_template)\n"
   ],
   "id": "7abd439dc2f71bd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DatasetLoad:\n",
    "    def __init__(self, dataset_type, base_path, percentage=100.0, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize the DatasetLoad object.\n",
    "\n",
    "        :param dataset_type: Type of the dataset ('emotion', 'sarcasm', or 'tweets').\n",
    "        :param base_path: Base path where dataset files are located.\n",
    "        :param percentage: Percentage of the dataset to use.\n",
    "        \"\"\"\n",
    "        self.dataset_type = dataset_type\n",
    "        self.base_path = base_path\n",
    "        self.percentage = percentage\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.val_data = None\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Load the tweet dataset from a CSV file.\n",
    "\n",
    "        :param file_path: Relative path to the tweet dataset file.\n",
    "        :return: DataFrame containing the tweet data.\n",
    "        \"\"\"\n",
    "        full_path = os.path.join(self.base_path, file_path)\n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"File not found: {full_path}\")\n",
    "        data = pd.read_csv(full_path, delimiter=',')\n",
    "        return data\n",
    "\n",
    "    def load_datasets(self):\n",
    "        \"\"\"\n",
    "        Load the datasets based on the dataset type and apply percentage sampling if needed.\n",
    "        Ensure the first column is 'text' and the second column is 'category'.\n",
    "        \"\"\"\n",
    "        if self.dataset_type == 'reddit':\n",
    "            print(\"Loading Reddit dataset...\")\n",
    "            data = self.load_data('datasets/Reddit_Data.csv')\n",
    "            data = data.rename(columns={'clean_comment': 'text'})\n",
    "            # truncate the text in the text column with over 512 characters\n",
    "            data['text'] = data['text'].str.slice(0, 512)\n",
    "\n",
    "\n",
    "        elif self.dataset_type == 'tweets':\n",
    "            print(\"Loading Twitter dataset...\")\n",
    "            data = self.load_data('datasets/Twitter_Data.csv')\n",
    "            # drop the ID column, axis=1\n",
    "            data = data.drop('Id', axis=1)\n",
    "            # convert category from text to -1, 0, 1\n",
    "            data['category'] = data['Category'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n",
    "            data = data.drop('Category', axis=1)\n",
    "            # rename 'tweet' column to 'text'\n",
    "            data = data.rename(columns={'Tweet': 'text'})\n",
    "            # remove the rows of the text column in which the text is \"Not Available\"\n",
    "            data = data[data['text'] != 'Not Available']\n",
    "            data = data.dropna()\n",
    "\n",
    "        # Ensure the first column is 'text' and the second column is 'category'\n",
    "        data = data[['text', 'category'] + [col for col in data.columns if col not in ['text', 'category']]]\n",
    "\n",
    "        train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        self.val_data, self.test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "        self.train_data = train_data\n",
    "\n",
    "        if self.percentage < 100.0:\n",
    "            self.train_data = self.train_data.sample(frac=self.percentage / 100.0, random_state=42)\n",
    "            self.val_data = self.val_data.sample(frac=self.percentage / 100.0, random_state=42)\n",
    "            self.test_data = self.test_data.sample(frac=self.percentage / 100.0, random_state=42)"
   ],
   "id": "eeb59318e64b95c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "        self.device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, ignore_mismatched_sizes=True).to(self.device)\n",
    "        self.classifier = pipeline(\"sentiment-analysis\", model=self.model, tokenizer=self.tokenizer, device=self.device)\n",
    "\n",
    "        # Initialize FLAN model for synthetic data generation\n",
    "        self.flan_model_name = \"google/flan-t5-small\"\n",
    "        self.flan_tokenizer = AutoTokenizer.from_pretrained(self.flan_model_name)\n",
    "        self.flan_model = AutoModelForSeq2SeqLM.from_pretrained(self.flan_model_name).to(self.device)\n",
    "    def analyze_sentiment(self, text):\n",
    "        results = self.classifier(text)\n",
    "        return results[0]['label']\n",
    "\n",
    "    def map_label_to_target(self, label):\n",
    "        # Map the sentiment label to the target value\n",
    "        if label == \"negative\" or label == \"Negative\":\n",
    "            return 0\n",
    "        elif label == \"neutral\" or label == \"Neutral\":\n",
    "            return 1\n",
    "        elif label == \"positive\" or label == \"Positive\":\n",
    "            return 2\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Generate synthetic data using the FLAN model\n",
    "    def generate_synthetic_data(self, topic, text, sentiment, n_samples):\n",
    "        synthetic_data = []\n",
    "        for _ in range(n_samples):\n",
    "            prompt = f\"Generate a tweet related to {topic} that expresses a {sentiment} sentiment similar to: '{text}' \"\n",
    "            inputs = self.flan_tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "            outputs = self.flan_model.generate(inputs.input_ids, max_length=60, num_return_sequences=1)\n",
    "            generated_text = self.flan_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            synthetic_data.append(generated_text)\n",
    "        return synthetic_data\n",
    "\n",
    "    # Augment the training data with synthetic data\n",
    "    def augment_training_data(self, topics, texts, sentiments, n_samples=6):\n",
    "        augmented_data = {'text': [], 'label': []}\n",
    "        augmented_data_with_topics = {'text': [], 'label': [], 'topic': []}\n",
    "\n",
    "        for topic, text, sentiment in zip(topics, texts, sentiments):\n",
    "            synthetic_texts = self.generate_synthetic_data(topic, text, sentiment, n_samples)\n",
    "            sentiment_label = self.map_label_to_target(sentiment)\n",
    "            augmented_data['text'].extend(synthetic_texts)\n",
    "            augmented_data['label'].extend([sentiment_label] * len(synthetic_texts))\n",
    "            augmented_data_with_topics['text'].extend(synthetic_texts)\n",
    "            augmented_data_with_topics['label'].extend([sentiment_label] * len(synthetic_texts))\n",
    "            augmented_data_with_topics['topic'].extend([topic] * len(synthetic_texts))\n",
    "\n",
    "        augmented_df = pd.DataFrame(augmented_data)\n",
    "        augmented_df_with_topics = pd.DataFrame(augmented_data_with_topics)\n",
    "        return augmented_df, augmented_df_with_topics\n",
    "\n",
    "    # Fine-tune the model with augmented data\n",
    "    def fine_tune_with_augmented_data(self, topics, texts, sentiments, n_samples=6, epochs=3, batch_size=16,\n",
    "                                      learning_rate=2e-5):\n",
    "        augmented_train_data, augmented_train_data_with_topics = self.augment_training_data(topics, texts, sentiments,\n",
    "                                                                                            n_samples)\n",
    "        return self.fine_tune(augmented_train_data, epochs, batch_size, learning_rate), augmented_train_data_with_topics\n",
    "\n",
    "    # Fine-tune the model on a custom dataset\n",
    "    def fine_tune(self, df, epochs=3, batch_size=16, learning_rate=2e-5):\n",
    "        # Preprocess the dataset\n",
    "        df = df.rename(columns={\"text\": \"text\", \"category\": \"label\"})     # Rename the columns\n",
    "        df['label'] = df['label'].astype(int)   # Ensure the labels are integers\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)        # Split the dataset\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df)   # Load the dataset\n",
    "        test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "        def tokenize_function(examples):    # Tokenize the text\n",
    "            return self.tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "        train_dataset = train_dataset.map(tokenize_function, batched=True)  # Tokenize the dataset\n",
    "        test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "        train_dataset = train_dataset.remove_columns([\"text\"])  # Remove the text column after tokenization\n",
    "        test_dataset = test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "        train_dataset.set_format(\"torch\")   # Set the format to PyTorch\n",
    "        test_dataset.set_format(\"torch\")\n",
    "\n",
    "        # Define the data collator\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "\n",
    "        # Define training arguments\n",
    "        training_args = TrainingArguments(  # Define the training arguments\n",
    "            output_dir=\"./results\",\n",
    "            run_name=\"finetuning_sentiment_classifier\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=0.01,\n",
    "        )\n",
    "\n",
    "        # Define the trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        # Fine-tune the model\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluate the model\n",
    "        results = trainer.evaluate()\n",
    "        print(results)\n",
    "        return results\n"
   ],
   "id": "5834df24d21707f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set the base path\n",
    "base_path = os.getcwd()\n",
    "\n",
    "# Load the dataset\n",
    "dataset_loader = DatasetLoad('tweets', base_path, 100.0)\n",
    "dataset_loader.load_datasets()\n",
    "original_train_data = dataset_loader.train_data\n",
    "original_test_data = dataset_loader.test_data\n",
    "original_val_data = dataset_loader.val_data\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "# Fine-tune or load the sentiment model\n",
    "model_save_path = os.path.join(base_path, 'sentiment_model_tweets_100.pt')\n",
    "if os.path.exists(model_save_path):\n",
    "    sentiment_analyzer.model = torch.load(model_save_path)\n",
    "else:\n",
    "    sentiment_analyzer.fine_tune(original_train_data)\n",
    "    torch.save(sentiment_analyzer.model, model_save_path)\n",
    "\n",
    "# Predict sentiment for the datasets\n",
    "train_sentiment_file_name = os.path.join(base_path, 'train_sentiment_tweets_100.csv')\n",
    "test_sentiment_file_name = os.path.join(base_path, 'test_sentiment_tweets_100.csv')\n",
    "val_sentiment_file_name = os.path.join(base_path, 'val_sentiment_tweets_100.csv')\n",
    "\n",
    "train_data_with_sentiment = predict_sentiment(original_train_data.copy(), sentiment_analyzer, train_sentiment_file_name)\n",
    "test_data_with_sentiment = predict_sentiment(original_test_data.copy(), sentiment_analyzer, test_sentiment_file_name)\n",
    "val_data_with_sentiment = predict_sentiment(original_val_data.copy(), sentiment_analyzer, val_sentiment_file_name)"
   ],
   "id": "be0481db3248ffff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute and print metrics\n",
    "train_true_labels = original_train_data['category']\n",
    "train_predicted_labels = train_data_with_sentiment['sentiment']\n",
    "print(\"\\nTrain Classification Report:\")\n",
    "print(classification_report(train_true_labels, train_predicted_labels, labels=[0, 1, 2], zero_division=0))\n",
    "\n",
    "test_true_labels = original_test_data['category']\n",
    "test_predicted_labels = test_data_with_sentiment['sentiment']\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(test_true_labels, test_predicted_labels, labels=[0, 1, 2], zero_division=0))\n",
    "\n",
    "val_true_labels = original_val_data['category']\n",
    "val_predicted_labels = val_data_with_sentiment['sentiment']\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(val_true_labels, val_predicted_labels, labels=[0, 1, 2], zero_division=0))"
   ],
   "id": "8dbdb0ab4e97472b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the metadata extractor\n",
    "extractor = MetadataExtractor()\n",
    "topic_labels = [\"politics\", \"entertainment\", \"sports\", \"technology\", \"health\", \"education\", \"finance\", \"food\", \"other\"]\n",
    "\n",
    "# Extract metadata for the datasets\n",
    "train_file_name = os.path.join(base_path, 'train_augmented_tweets_100.csv')\n",
    "test_file_name = os.path.join(base_path, 'test_augmented_tweets_100.csv')\n",
    "val_file_name = os.path.join(base_path, 'val_augmented_tweets_100.csv')\n",
    "\n",
    "train_data_with_metadata = augment_and_extract_metadata(train_data_with_sentiment.copy(), extractor, topic_labels, train_file_name)\n",
    "test_data_with_metadata = augment_and_extract_metadata(test_data_with_sentiment.copy(), extractor, topic_labels, test_file_name)\n",
    "val_data_with_metadata = augment_and_extract_metadata(val_data_with_sentiment.copy(), extractor, topic_labels, val_file_name)\n",
    "\n",
    "# Function to create subgroups based on metadata\n",
    "def create_subgroups(dataset):\n",
    "    subgroups = {}\n",
    "    for topic in topic_labels:\n",
    "        subgroup_name = f\"{topic}\"\n",
    "        subgroups[subgroup_name] = dataset[dataset['topic'] == topic]\n",
    "    return subgroups\n",
    "\n",
    "train_subgroups = create_subgroups(train_data_with_metadata)\n",
    "test_subgroups = create_subgroups(test_data_with_metadata)\n",
    "val_subgroups = create_subgroups(val_data_with_metadata)"
   ],
   "id": "3ea634ca0e548931"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to compute metrics for the subgroups\n",
    "def compute_metrics(subgroups, true_labels_column='category', pred_labels_column='sentiment'):\n",
    "    metrics = []\n",
    "    for topic, subgroup in subgroups.items():\n",
    "        if not subgroup.empty:\n",
    "            true_labels = subgroup[true_labels_column]\n",
    "            pred_labels = subgroup[pred_labels_column]\n",
    "            report = classification_report(true_labels, pred_labels, output_dict=True, zero_division=0)\n",
    "            metrics.append({\n",
    "                'topic': topic,\n",
    "                'accuracy': report['accuracy'],\n",
    "                'precision': report['weighted avg']['precision'],\n",
    "                'recall': report['weighted avg']['recall'],\n",
    "                'f1-score': report['weighted avg']['f1-score']\n",
    "            })\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "train_metrics = compute_metrics(train_subgroups)\n",
    "test_metrics = compute_metrics(test_subgroups)\n",
    "val_metrics = compute_metrics(val_subgroups)\n",
    "\n",
    "print(\"Train Metrics per Topic\")\n",
    "print(train_metrics)\n",
    "print(\"\\nTest Metrics per Topic\")\n",
    "print(test_metrics)\n",
    "print(\"\\nValidation Metrics per Topic\")\n",
    "print(val_metrics)"
   ],
   "id": "f4c088900f21ff56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to analyze disparities in sentiment predictions\n",
    "def analyze_disparities(subgroups):\n",
    "    analysis_results = []\n",
    "    for subgroup_name, subgroup_data in subgroups.items():\n",
    "        if not subgroup_data.empty:\n",
    "            sentiment_counts = subgroup_data['sentiment'].value_counts(normalize=True) * 100\n",
    "            analysis_results.append({\n",
    "                'subgroup': subgroup_name,\n",
    "                'total': len(subgroup_data),\n",
    "                'negative': sentiment_counts.get(0, 0),\n",
    "                'neutral': sentiment_counts.get(1, 0),\n",
    "                'positive': sentiment_counts.get(2, 0),\n",
    "            })\n",
    "    return pd.DataFrame(analysis_results)\n",
    "\n",
    "train_analysis = analyze_disparities(train_subgroups)\n",
    "test_analysis = analyze_disparities(test_subgroups)\n",
    "val_analysis = analyze_disparities(val_subgroups)\n",
    "\n",
    "print(\"Train Percentage Analysis\")\n",
    "print(train_analysis)\n",
    "print(\"\\nTest Percentage Analysis\")\n",
    "print(test_analysis)\n",
    "print(\"\\nValidation Percentage Analysis\")\n",
    "print(val_analysis)"
   ],
   "id": "7c1a43bda15554f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def weighted_metrics(metrics_df, support_df, metric='accuracy'):\n",
    "    metrics_df = metrics_df.copy()\n",
    "    metrics_df = metrics_df.merge(support_df, left_on='topic', right_on='subgroup')\n",
    "    metrics_df['weighted_metric'] = metrics_df[metric] * metrics_df['support']\n",
    "    return metrics_df\n",
    "\n",
    "def get_top_lower_topics(test_metrics_df, test_percentage_analysis_df, metric='accuracy'):\n",
    "    support_df = test_percentage_analysis_df[['subgroup', 'total']].rename(columns={'total': 'support'})\n",
    "    weighted_metrics_df = weighted_metrics(test_metrics_df, support_df, metric)\n",
    "    baseline_accuracy = weighted_metrics_df['accuracy'].mean()\n",
    "    sorted_metrics = weighted_metrics_df.sort_values(by='weighted_metric', ascending=False)\n",
    "    top_3_topics = sorted_metrics.head(3)['topic'].tolist()\n",
    "    bottom_3_topics = sorted_metrics.tail(3)['topic'].tolist()\n",
    "    bottom_3_topics_below_baseline = sorted_metrics[sorted_metrics['accuracy'] < baseline_accuracy].tail(3)['topic'].tolist()\n",
    "    return top_3_topics, bottom_3_topics_below_baseline\n",
    "\n",
    "topics = get_top_lower_topics(val_metrics, val_analysis, metric='accuracy')\n",
    "print(f\"Top 3 (lower score) validation topics: {topics[0]}\")"
   ],
   "id": "65e1256af171ba38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_and_augment_data(sentiment_analyzer, topics, train_data_with_metadata, n_samples):\n",
    "    if isinstance(topics[0], list):\n",
    "        topics = [item for sublist in topics for item in sublist]\n",
    "    synthetic_texts = []\n",
    "    for topic in topics:\n",
    "        topic_data = train_data_with_metadata[train_data_with_metadata['topic'] == topic]\n",
    "        topic_samples = topic_data.sample(n_samples, replace=True)\n",
    "        for index, row in topic_samples.iterrows():\n",
    "            synthetic_texts.extend(sentiment_analyzer.generate_synthetic_data(row['topic'], row['text'], n_samples))\n",
    "    return synthetic_texts\n",
    "\n",
    "synthetic_texts = generate_and_augment_data(sentiment_analyzer, topics, train_data_with_metadata, n_samples=10)\n",
    "synthetic_df = pd.DataFrame({\n",
    "    'text': synthetic_texts,\n",
    "    'category': [1] * len(synthetic_texts),\n",
    "    'topic': topics[1] * (len(synthetic_texts) // len(topics[1]))\n",
    "})\n",
    "\n",
    "augmented_train_data = pd.concat([original_train_data, synthetic_df], ignore_index=True)\n",
    "augmented_fine_tuning_results = sentiment_analyzer.fine_tune(augmented_train_data)\n",
    "print(f\"Fine-tuning results with augmented data: {augmented_fine_tuning_results}\")\n"
   ],
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
